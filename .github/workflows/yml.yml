name: Hourly Instagram Scrape

on:
  workflow_dispatch:
  schedule:
    - cron: '0 * * * *'  # every hour at minute 0 (UTC)

jobs:
  scrape:
    runs-on: ubuntu-latest

    # Grant permissions for the action to push to your repo
    permissions:
      contents: write

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Set up Chrome + ChromeDriver
        id: setup-chrome
        uses: browser-actions/setup-chrome@v1
        with:
          # Be explicit to ensure the action finds a matching pair
          chrome-version: stable 

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          # Removed webdriver-manager, as it's not needed for the action
          pip install selenium requests

      - name: Run scraper
        env:
          CHROME_PATH: ${{ steps.setup-chrome.outputs.chrome-path }}
          CHROMEDRIVER_PATH: ${{ steps.setup-chrome.outputs.chromedriver-path }}
          INSTAGRAM_SESSION_ID: ${{ secrets.INSTAGRAM_SESSION_ID }}
        run: python main.py

      - name: Commit and push changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "ðŸ“Š Scraper Data Update"
          file_pattern: "profile_log.csv profile_pics/* last_pic_url.txt"
          commit_user_name: "GitHub Actions Bot"
          commit_user_email: "github-actions@github.com"
          commit_author: "GitHub Actions Bot <github-actions@github.com>"
